{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.nitrc.org/plugins/mwiki/index.php/neurobureau:AthenaPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from Code.data_generator import FMRIDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Conv3D, MaxPool3D, TimeDistributed, Flatten, LSTM, Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import logging\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ DATA WORK ============================\n",
    "\n",
    "file_num = sys.argv[1]\n",
    "\n",
    "# Dataframes\n",
    "dataset_dir = \"/pylon5/cc5614p/deopha32/fmri_images/model_data/\"\n",
    "model_train_data = pd.read_csv(\"/home/deopha32/ADHD-FMRI/Data/training_data_{}\".format(file_num) )\n",
    "model_val_data = pd.read_csv(\"/home/deopha32/ADHD-FMRI/Data/validatation_data_{}\".format(file_num) )\n",
    "\n",
    "# Dictionary of data values\n",
    "partition = {'train': model_train_data['Image'].values, \n",
    "             'validation': model_val_data['Image'].values}\n",
    "\n",
    "# Training Data\n",
    "train_labels = {}\n",
    "for index, row in model_train_data.iterrows():\n",
    "    train_labels[row['Image']] = row['DX']\n",
    "    \n",
    "# Validation Data\n",
    "val_labels = {}\n",
    "for index, row in model_val_data.iterrows():\n",
    "    val_labels[row['Image']] = row['DX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ MODEL META ============================\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 6\n",
    "input_shape=(177,28,28,28,1)\n",
    "\n",
    "train_steps_per_epoch = model_train_data.shape[0] // batch_size\n",
    "validate_steps_per_epoch = model_val_data.shape[0] // batch_size\n",
    "\n",
    "# Generators\n",
    "training_generator = FMRIDataGenerator(partition['train'], train_labels, dataset_dir, batch_size)\n",
    "validation_generator = FMRIDataGenerator(partition['validation'], val_labels, dataset_dir, batch_size)\n",
    "\n",
    "curr_time = f'{datetime.now():%H-%M-%S%z_%m%d%Y}'\n",
    "logger_path = \"/pylon5/cc5614p/deopha32/Saved_Models/adhd-fmri-history_cv{num}_{time}.csv\".format(num=file_num,time=curr_time)\n",
    "\n",
    "csv_logger = CSVLogger(logger_path, append=True)\n",
    "\n",
    "callbacks = [csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ MODEL ARCHITECTURE ============================\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    cnn_lstm_model = Sequential()\n",
    "\n",
    "    cnn_lstm_model.add(TimeDistributed(Conv3D(filters=64,kernel_size=(3,3,3),activation='relu'),\n",
    "                                  input_shape=input_shape, name=\"Input_Conv_Layer\"))\n",
    "\n",
    "    cnn_lstm_model.add(TimeDistributed(MaxPool3D(\n",
    "                                    pool_size=(2, 2, 2),\n",
    "                                    strides=(2, 2, 2),\n",
    "                                    padding='valid'\n",
    "                                    ), name=\"Pool_Layer_1\"))\n",
    "\n",
    "    cnn_lstm_model.add(TimeDistributed(Flatten(), name=\"Flatten_Layer\"))\n",
    "    \n",
    "with tf.device('/cpu:0'):\n",
    "\n",
    "    cnn_lstm_model.add(LSTM(10, dropout = 0.3, recurrent_dropout = 0.3, name=\"LSTM_Layer\"))\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "\n",
    "    cnn_lstm_model.add(Dense(1, activation = 'sigmoid', name=\"Output_Dense_Layer\"))\n",
    "\n",
    "    cnn_lstm_model.compile(optimizer=optimizers.Adam(lr=0.0001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "cnn_lstm_model.fit_generator(generator=training_generator,\n",
    "    steps_per_epoch=train_steps_per_epoch, verbose=1, callbacks=callbacks,\n",
    "    validation_data=validation_generator, validation_steps=validate_steps_per_epoch,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/46216013/9221241\n",
    "def get_model_memory_usage(batch_size, model):\n",
    "    import numpy as np\n",
    "    from keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    internal_model_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        layer_type = l.__class__.__name__\n",
    "        if layer_type == 'Model':\n",
    "            internal_model_mem_count += get_model_memory_usage(batch_size, l)\n",
    "        # Ensure output shape exists\n",
    "        if hasattr(l, 'output_shape'):\n",
    "            out_shape = l.output_shape\n",
    "        elif hasattr(l, 'compute_output_shape'):\n",
    "            out_shape = l.compute_output_shape(l.input_shape)\n",
    "        else:\n",
    "            continue  # skip layers without shape information\n",
    "\n",
    "        single_layer_mem = 1\n",
    "        for s in out_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "\n",
    "    number_size = 4.0\n",
    "    if K.floatx() == 'float16':\n",
    "         number_size = 2.0\n",
    "    if K.floatx() == 'float64':\n",
    "         number_size = 8.0\n",
    "\n",
    "    total_memory = number_size*(batch_size*shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3) + internal_model_mem_count\n",
    "    return gbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_memory_usage(32, cnn_lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
